print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: Omega = ", Omega))
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: prob_negative_return = ", prob_negative_return))
# OBJECTIVE FUNCTION
####################
Omega = 11520
#Get the expected returns and var-covar matrix:
df = df_sim
x_bar = as.numeric(colMeans(df))
Sigma = as.matrix(cov(df))
#Investor weights:
theta = c(0.01,1+eps)
#Transformation to standard quadprog notation:
d = theta[1] * x_bar
D = theta[2] * Sigma
# CONSTRAINTS
#############
#Initiate matrix A of linear constraints:
#Weights sum up to 1, one equality constraint:
A = matrix(1,1,K)
b = c(1)
# Weights equal to constraint:
number_of_equality_constraints = 1
for (k in 1:K) {
if (!is.na(hard_constraints_percentage_df["equal_to",k])) {
temp = matrix(0,1,K)
temp[1,k] = 1
A = rbind(A,temp)
b = append(b,hard_constraints_percentage_df["equal_to",k])
number_of_equality_constraints = number_of_equality_constraints + 1
}
}
# Amounts equal to constraint:
if (!is.na(Omega)) { # If portfolio size is set, assign weights proportionally:
for (k in 1:K) {
if (!is.na(hard_constraints_amount_df["equal_to",k])) {
temp = matrix(0,1,K)
temp[1,k] = 1
A = rbind(A,temp)
b = append(b,hard_constraints_amount_df["equal_to",k]/Omega)
number_of_equality_constraints = number_of_equality_constraints + 1
}
}
} else { #Otherwise, set the dependencies between assets:
for (k1 in 1:K) {
if (!is.na(hard_constraints_amount_df["equal_to",k1])) {
break # Find the first asset with amount equal to constraint
}
}
for (k2 in (k1+1):K) {
if (!is.na(hard_constraints_amount_df["equal_to",k2])) {
temp = matrix(0,1,K)
temp[1,k1] = hard_constraints_amount_df["equal_to",k2]
temp[1,k2] = - hard_constraints_amount_df["equal_to",k1]
A = rbind(A,temp)
b = append(b,0)
number_of_equality_constraints = number_of_equality_constraints + 1
}
}
}
#Weights non-negative:
A = rbind(A,-diag(K))
b = append(b, 0*numeric(K))
#Weights bigger than lower bound:
A = rbind(A,-diag(K))
b = append(b,-as.numeric(hard_constraints_percentage_df["lower_limit",]))
#Weights lower than upper bound:
A = rbind(A,diag(K))
b = append(b,as.numeric(hard_constraints_percentage_df["upper_limit",]))
#Expected return greater than:
for (constraint in constraints) {
if (constraint$name == "MinExpReturnX") {
min_return = constraint$params[1]
A = rbind(A, -x_bar)
b = append(b, -min_return)
}
}
L = length(b)
################################################################################
# Solve it
################################################################################
test = solve.QP(Dmat = D, dvec = d, Amat = -t(A), bvec = -b, meq=number_of_equality_constraints, factorized = FALSE)
# test = ipop(-d, D, A, -1/eps*(numeric(L)+1), -1/eps*(numeric(K)+1), 1/eps*(numeric(K)+1), 1/eps*(numeric(L)+1) + b)
w = round(test$solution,4)
expected_return = w %*% x_bar
variance = w %*% Sigma %*% w
for (k in 1:K) {
if (!is.na(hard_constraints_amount_df["equal_to", k])) {
Omega = hard_constraints_amount_df["equal_to", k] / w[k]
}
}
c_var_return_0.05 = mean(sort(as.matrix(df) %*% w)[1:floor(0.05*N)])
c_var_amount_0.05 = - c_var_return_0.05 * Omega
prob_negative_return = sum((as.matrix(df) %*% w)<0)/N
for (k in 1:K) {
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: w",k , " = ", w[k]*100, "%"))
}
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: expected_return = ", expected_return))
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: variance = ", variance))
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: cvar_return_0.05 = ", c_var_return_0.05))
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: cvar_amount_0.05 = ", c_var_amount_0.05))
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: Omega = ", Omega))
print(paste0(Sys.time(), ": OPTIMAL PORTFOLIO: prob_negative_return = ", prob_negative_return))
################################################################################
# INSTALL DEPENDENCIES
# ################################################################################
# install.packages("cli")
# install.packages("cramer")
# install.packages("data.table")
# install.packages("devtools")
# install.packages("gclus")
# install.packages("MASS")
# install.packages("moments")
# install.packages("PearsonDS")
# install.packages("readxl")
# install.packages("Rcpp")
# install.packages("Rfast")
# install.packages('stringr')
# install.packages('TSP')
# install.packages("VineCopula")
################################################################################
# DEPENDENCIES
################################################################################
path_root = "/media/juro/DATA/Work/NBS/PortfolioOptimization/"
# path_root = "C:/Users/jhledik/Desktop/PortfolioOptimization/"
library(cli)
library(cramer)
library(data.table)
library(gclus)
library(MASS)
library(moments)
library(PearsonDS)
library(readxl)
library(Rfast)
library(stringr)
library(TSP)
library(VineCopula)
source(paste0(path_root, "code/R/config.R"))
################################################################################
# DATA IMPORT
################################################################################
df <- read_excel(paste0(path_data,"indexy1.xls"))
df = df[complete.cases(df),]
df = df[order(df$Date),]
df <- df[2:ncol(df)] # get data
df[,] <- sapply(df[,], as.character)
df[,] <- sapply(df[,], as.numeric)
N = nrow(df)
K = ncol(df)
asset_names = names(df)
asset_names_no_escape = str_replace(asset_names,"/", " ")
################################################################################
# INSTALL DEPENDENCIES
# ################################################################################
# install.packages("cli")
# install.packages("cramer")
# install.packages("data.table")
# install.packages("devtools")
# install.packages("gclus")
# install.packages("MASS")
# install.packages("moments")
# install.packages("PearsonDS")
# install.packages("readxl")
# install.packages("Rcpp")
# install.packages("Rfast")
# install.packages('stringr')
# install.packages('TSP')
# install.packages("VineCopula")
################################################################################
# DEPENDENCIES
################################################################################
path_root = "/media/juro/DATA/Work/NBS/PortfolioOptimization/"
# path_root = "C:/Users/jhledik/Desktop/PortfolioOptimization/"
library(cli)
library(cramer)
library(data.table)
library(gclus)
library(MASS)
library(moments)
library(PearsonDS)
library(readxl)
library(Rfast)
library(stringr)
library(TSP)
library(VineCopula)
source(paste0(path_root, "code/R/config.R"))
################################################################################
# DATA IMPORT
################################################################################
df <- read_excel(paste0(path_data,"indexy1.xls"))
df = df[complete.cases(df),]
df = df[order(df$Date),]
df <- df[2:ncol(df)] # get data
df[,] <- sapply(df[,], as.character)
df[,] <- sapply(df[,], as.numeric)
N = nrow(df)
K = ncol(df)
asset_names = names(df)
asset_names_no_escape = str_replace(asset_names,"/", " ")
################################################################################
# DIRECTORY CREATION
################################################################################
dir.create(file.path(path_model_output), showWarnings = FALSE)
dir.create(file.path(path_model_output_figures), showWarnings = FALSE)
################################################################################
# PLOT CORRELATIONS
################################################################################
#STANDARD LINEAR:
df.r <- abs(cor(df)) # get correlations
df.col <- dmat.color(df.r) # get colors
# reorder variables so those with highest correlation
# are closest to the diagonal
df.o <- order.single(df.r)
#Plot
dir.create(file.path(paste0(path_model_output_figures,"correlations/")), showWarnings = FALSE)
png(paste0(path_model_output_figures,"correlations/","Historical_Returns",".png"), width = 2000, height = 2000)
cpairs(df, gap=.5, main="Historical returns" )
dev.off()
# #KENDALL:
# mydata <- data.frame(x,y)
# cor(df, method = "kendall")
################################################################################
# GET MOMENTS, ESTIMATE DISTRIBUTION
################################################################################
x = df$`1-5 Year US Govt (ICE) FX Unhdg.`
x = df$`1-3 Year China Govt (ICE) FX Unhdg.`
x = df$`Gold XAU/EUR Rate FX Unhdg.`
x = df$`1-5 Year Global Non-Sov (ICE) IR hdg. IRS`
x = df$`World Equity (MSCI) FX Unhdg.`
x = df$`US Inflation-Linked Govt (ICE) FX Hdg.`
x = df$`US MBS (ICE) FX Hdg.`
x = df$`EM global IG Govt (JPM) FX Hdg.`
x = df$`1-5 Year Global Non-Sov (ICE) IR hdg. IRS`
y = df$`1-5 Year US Govt (ICE) FX Unhdg.`
x_mean <- mean(x)
x_var <- var(x)
x_rate <- x_mean / x_var
x_shape <- ( (x_mean)^2 ) / x_var
x_skew = skewness(x)
x_kurt = kurtosis(x)
# parameters of the pearson type 7 distribution:
mu = x_mean
nu =(6 - 4*x_kurt) / (3 - x_kurt)
sigma = sqrt(x_var) * sqrt((nu-2)/nu)
temp1 = rpearsonVII(1000000, nu, mu, sigma)
temp2 = rnorm(1000000, mu, sqrt(x_var))
xrange = range(c(-3*sqrt(x_var), 3*sqrt(x_var)))
kurtosis(temp1)
kurtosis(temp2)
hg1 = density(temp1)
hg2 = density(temp2)
hist(x, # histogram
col = "peachpuff", # column color
border = "black",
prob = TRUE, # show densities instead of frequencies
xlim = xrange,
breaks=50)
lines(hg1, xlim=xrange, col = "red")
lines(hg2, xlim=xrange, col = "blue")
################################################################################
# EXPORT MARGINAL DISTRIBUTIONS' FIGURES AND CONVERT THE DATA TO [0,1]^N
################################################################################
df_U = df
param_marginals = data.frame(index = numeric(),
nu = numeric(),
mu = numeric(),
sigma = numeric(),
stringsAsFactors = FALSE)
#Go through the individual variables:
k =5
#For each asset class, fit the pearson VII distribution:
for (k in 1:K) {
print(paste0(Sys.time(), ": UNIFORM TRANSFORMATION: Processing asset ", k, " of ", K, "."))
#Load the asset class observations:
x =  as.vector(df[[asset_names[k]]])
#Find its mean, variance, rate, shape, skewness and kurtosis:
x_mean <- mean(x)
x_var <- var(x)
x_rate <- x_mean / x_var
x_shape <- ( (x_mean)^2 ) / x_var
x_skew = skewness(x)
x_kurt = kurtosis(x)
# Compute the Pearson type VII parameters:
mu = x_mean
nu =(6 - 4*x_kurt) / (3 - x_kurt)
sigma = sqrt(x_var) * sqrt((nu-2)/nu)
#Generate simulated observations from the estimated distribution and also from
#the normal distribution.
temp1 = rpearsonVII(1000000, nu, mu, sigma)
temp2 = rnorm(1000000, mu, sqrt(x_var))
#Set x axis plot limits:
xrange = range(c(-3*sqrt(x_var), 3*sqrt(x_var)))
#Get the empirical densities:
hg1 = density(temp1)
hg2 = density(temp2)
#Save the resulting figure within the specified folder
dir.create(file.path(paste0(path_model_output_figures,"marginal_distributions/")), showWarnings = FALSE)
png(paste0(path_model_output_figures,"marginal_distributions/",asset_names_no_escape[k],".png"), width = 800, height = 800)
hist(x, # histogram
col = "peachpuff", # column color
border = "black",
prob = TRUE, # show densities instead of frequencies
xlim = xrange,
breaks=50,
main = asset_names[k])
lines(hg1, xlim=xrange, col = "red", lwd=2)
lines(hg2, xlim=xrange, col = "blue", lwd=2, lty="dashed")
legend("topright",
legend=c(paste0("Pearson type VII fit \n","mu=",round(mean(temp1),2),", sigma=",round(sqrt(var(temp1)),2),", kurt=",round(kurtosis(temp1),2)),
paste0("Normal fit \n","mu=",round(mean(temp2),2),", sigma=",round(sqrt(var(temp2)),2),", kurt=",round(kurtosis(temp2),2))),
col=c("red", "blue"), lty=1:2, cex=1, lwd = 2, y.intersp=2)
dev.off()
# Transform the returns into a [0,1] uniformly distributed variable and update
# the relevant dataframe.
U = ppearsonVII(x, nu, mu, sigma)
df_U[[asset_names[k]]] = U
#Save the histogram to see how uniform the data is:
dir.create(file.path(paste0(path_model_output_figures,"marginal_distributions_uniform/")), showWarnings = FALSE)
png(paste0(path_model_output_figures,"marginal_distributions_uniform/",asset_names_no_escape[k],".png"), width = 800, height = 800)
hist(U, # histogram
col = "peachpuff", # column color
border = "black",
prob = TRUE, # show densities instead of frequencies
xlim = range(0,1),
breaks=10,
main = paste0("Uniform transformation: \n", asset_names[k]))
dev.off()
#Append the marginal distribution parameter values:
df_temp<-data.frame(k,nu,mu,sigma)
names(df_temp)<-c("index","nu","mu","sigma")
param_marginals <- rbind(param_marginals, df_temp)
}
#Append the asset classes' names to the parameter dataframe:
param_marginals$asset_names = asset_names
param_marginals <- param_marginals[, c(1, 5, 2, 3, 4)]
################################################################################
# FIT THE MODEL
################################################################################
RVM <- RVineStructureSelect(df_U, familyset = c(1:8), progress = TRUE)
## see the object's content or a summary
str(RVM)
summary(RVM)
RVM$Matrix
df_sim_U = as.data.frame(RVineSim(60*N,RVM))
df_sim_60 = df_sim_U
for (k in 1:K) {
#Import the relevant simulated uniform asset:
u =  as.vector(df_sim_U[[asset_names[k]]])
#Import nu,mu,sigma:
nu = as.vector(param_marginals[["nu"]])[k]
mu = as.vector(param_marginals[["mu"]])[k]
sigma = as.vector(param_marginals[["sigma"]])[k]
#Transform the asset:
df_sim_60[[asset_names[k]]] = qpearsonVII(u, nu, mu, sigma)
}
df_sim = df_sim_60[1:N,]
library(shiny); source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
library(shiny); source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
source('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB/deploy.R')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
constraints_df = data.frame(read_excel(paste0(path_data,"portfolio_constraints.xlsx")))
lower_limit_percentages = as.vector(constraints_df$perc_min)
View(constraints_df)
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp()
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp()
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp()
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp()
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
results$expected_profit = expected_return * Omega
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp()
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/ShinyAB')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/code/R')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
library(rsconnect)
################################################################################
# RUN THE APP
########################################### #####################################
rsconnect::deployApp("/media/juro/DATA/Work/NBS/PortfolioOptimization/app")
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
df_sim_pa
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp()
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
install.packages("memuse")
library(memuse)
memuse::Sys.meminfo()
memuse::Sys.meminfo().Totalram
memuse::Sys.meminfo()$Totalram
temp = memuse::Sys.meminfo()
View(temp)
temp$totalram
temp = memuse::Sys.meminfo(compact.free=TRUE)
View(temp)
temp = memuse::Sys.meminfo(compact.free=FALSE)
View(temp)
temp$totalram
temp$totalram$size
temp$totalram.size
temp$totalram
str(temp$totalram)
str(temp$totalram@size)
temp$totalram@size
temp = memuse::Sys.meminfo(compact.free=FALSE)
temp$totalram@size
memory.limit(size = temp$totalram@size*1000/2)
temp = memuse::Sys.meminfo(compact.free=FALSE)
if(.Platform$OS.type == "windows") {
memory.limit(size = temp$totalram@size*1000/2)
}
.Platform$OS.type
devtools::install_github("krlmlr/ulimit")
library(ulimit)
temp = memuse::Sys.meminfo(compact.free=FALSE)
if(.Platform$OS.type == "windows") {
memory.limit(size = temp$totalram@size*1000/2)
} else if(.Platform$OS.type == "unix") {
ulimit::memory_limit(temp$totalram@size*1000/2)
}
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp()
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
load("~/Downloads/network_df_firms_in_total.Rdata")
#Install these packages. Once installed, comment this section, you don't need to run it again.
# install.packages('sqldf')
# install.packages('lubridate')
# install.packages('ggplot2')
# install.packages('foreach')
# install.packages('doParallel')
#Tell R which packages to use:
library(sqldf)
library(lubridate)
library(ggplot2)
# library(foreach)
# library(doParallel)
#Specify the correct folder path:
path_data = "/media/juro/DATA/Work/JuroRobertoProject/RawData/"
path_output = "/media/juro/DATA/Work/JuroRobertoProject/FiguresJuro/"
path_output_data = "/media/juro/DATA/Work/JuroRobertoProject/CreatedDatasetsJuro/"
write.csv(network_df, paste0(path_output_data,'network_df_firms_in_total.csv'), row.names = FALSE)
shiny::runApp('/media/juro/DATA/Work/NBS/PortfolioOptimization/app')
